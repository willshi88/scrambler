{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, CuDNNLSTM, CuDNNGRU, BatchNormalization, LocallyConnected2D, Permute, TimeDistributed, Bidirectional\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random, os, h5py, math, time, glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IdentityEncoder :\n",
    "    \n",
    "    def __init__(self, seq_len, channel_map) :\n",
    "        self.seq_len = seq_len\n",
    "        self.n_channels = len(channel_map)\n",
    "        self.encode_map = channel_map\n",
    "        self.decode_map = {\n",
    "            val : key for key, val in channel_map.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        encoding = np.zeros((self.seq_len, self.n_channels))\n",
    "        \n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        seq = ''\n",
    "    \n",
    "        for pos in range(0, encoding.shape[0]) :\n",
    "            argmax_nt = np.argmax(encoding[pos, :])\n",
    "            max_nt = np.max(encoding[pos, :])\n",
    "            if max_nt == 1 :\n",
    "                seq += self.decode_map[argmax_nt]\n",
    "            else :\n",
    "                seq += self.decode_map[-1]\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        encoding = np.array(encoding_mat[row_index, :].todense()).reshape(-1, 4)\n",
    "        return self.decode(encoding)\n",
    "\n",
    "class NopTransformer :\n",
    "    \n",
    "    def __init__(self, n_classes) :\n",
    "        self.n_classes = n_classes\n",
    "    \n",
    "    def transform(self, values) :\n",
    "        return values\n",
    "    \n",
    "    def transform_inplace(self, values, transform) :\n",
    "        transform[:] = values\n",
    "    \n",
    "    def transform_inplace_sparse(self, values, transform_mat, row_index) :\n",
    "        transform_mat[row_index, :] = np.ravel(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GRUClassifier(nn.Module) :\n",
    "    \n",
    "    def __init__(self, batch_size) :\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        \n",
    "        hid_numpy = np.zeros((1, batch_size, 64))\n",
    "        self.hid = Variable(torch.FloatTensor(hid_numpy))\n",
    "        \n",
    "        self.gru1_forward = nn.GRU(20, 64, bidirectional=False, num_layers=1, dropout=0.0)\n",
    "        self.gru1_backward = nn.GRU(20, 64, bidirectional=False, num_layers=1, dropout=0.0)\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.use_cuda = True if torch.cuda.is_available() else False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x.shape = (batch_size, 20, 1, 162)\n",
    "        x = x[:, :, 0, :].transpose(0, 1).transpose(0, 2)\n",
    "        #x.shape = (162, batch_size, 20)\n",
    "        x1 = x[:81, :, :]\n",
    "        x2 = x[81:, :, :]\n",
    "        \n",
    "        x1_forward = self.drop1(self.gru1_forward(x1, self.hid)[0])\n",
    "        x2_forward = self.drop1(self.gru1_forward(x2, self.hid)[0])\n",
    "        \n",
    "        x1_flipped = torch.flip(x1, (0,))\n",
    "        x2_flipped = torch.flip(x2, (0,))\n",
    "        \n",
    "        x1_backward = self.drop1(self.gru1_backward(x1_flipped, self.hid)[0])\n",
    "        x2_backward = self.drop1(self.gru1_backward(x2_flipped, self.hid)[0])\n",
    "        \n",
    "        #(seq_len, batch, num_directions * hidden_size)\n",
    "        x1_forward = x1_forward[-1, ...]\n",
    "        x2_forward = x2_forward[-1, ...]\n",
    "        \n",
    "        x1_backward = x1_backward[-1, ...]\n",
    "        x2_backward = x2_backward[-1, ...]\n",
    "        \n",
    "        x = torch.cat([x1_forward, x1_backward, x2_forward, x2_backward], dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pytorch model skeleton\n",
    "\n",
    "model_pytorch = GRUClassifier(batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load predictor\n",
    "\n",
    "def get_shared_model() :\n",
    "    \n",
    "    gru_1 = Bidirectional(GRU(64, activation='tanh', recurrent_activation='sigmoid', recurrent_dropout=0, unroll=False, use_bias=True, reset_after=True, return_sequences=False), merge_mode='concat', name='saved_bidir_1')\n",
    "    \n",
    "    drop_1 = Dropout(0.25)\n",
    "\n",
    "    def shared_model(inp) :\n",
    "\n",
    "        gru_1_out = gru_1(inp)\n",
    "        \n",
    "        drop_1_out = drop_1(gru_1_out)\n",
    "\n",
    "        return drop_1_out\n",
    "    \n",
    "    return shared_model\n",
    "\n",
    "shared_model = get_shared_model()\n",
    "\n",
    "#Inputs\n",
    "res_both = Input(shape=(1, 81 * 2, 19 + 1))\n",
    "\n",
    "[res_1, res_2] = Lambda(lambda x: [x[:, 0, :81, :], x[:, 0, 81:, :]])(res_both)\n",
    "\n",
    "#Outputs\n",
    "true_interacts = Input(shape=(1,))\n",
    "\n",
    "#Interaction model definition\n",
    "dense_out_1 = shared_model(res_1)\n",
    "dense_out_2 = shared_model(res_2)\n",
    "\n",
    "layer_dense_pair_1 = Dense(128, activation='relu', name='saved_dense_1')\n",
    "dense_out_pair = layer_dense_pair_1(Concatenate(axis=-1)([dense_out_1, dense_out_2]))\n",
    "\n",
    "pred_interacts = Dense(1, activation='linear', kernel_initializer='zeros', name='saved_dense_2')(dense_out_pair)\n",
    "pred_interacts_sigm = Activation('sigmoid')(pred_interacts)\n",
    "\n",
    "saved_predictor = Model(\n",
    "    inputs=[\n",
    "        res_both\n",
    "    ],\n",
    "    outputs=pred_interacts_sigm\n",
    ")\n",
    "\n",
    "saved_predictor.load_weights('saved_models/ppi_rnn_baker_big_set_5x_negatives_classifier_symmetric_drop_25_5x_negatives_balanced_partitioned_data_epoch_10.h5', by_name=False)\n",
    "saved_predictor.trainable = False\n",
    "\n",
    "saved_predictor.compile(\n",
    "    optimizer=keras.optimizers.SGD(lr=0.1),\n",
    "    loss='mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 162, 20)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 81, 20), (No 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "saved_bidir_1 (Bidirectional)   (None, 128)          33024       lambda_1[0][0]                   \n",
      "                                                                 lambda_1[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           saved_bidir_1[0][0]              \n",
      "                                                                 saved_bidir_1[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "saved_dense_1 (Dense)           (None, 128)          32896       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "saved_dense_2 (Dense)           (None, 1)            129         saved_dense_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           saved_dense_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 66,049\n",
      "Trainable params: 0\n",
      "Non-trainable params: 66,049\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect weights from keras model\n",
    "\n",
    "(\n",
    "    shuffled_gru_1_kernel_weight_forward,\n",
    "    shuffled_gru_1_recurrent_weight_forward,\n",
    "    shuffled_gru_1_bias_bundle_forward,\n",
    "    shuffled_gru_1_kernel_weight_backward,\n",
    "    shuffled_gru_1_recurrent_weight_backward,\n",
    "    shuffled_gru_1_bias_bundle_backward\n",
    ") = saved_predictor.get_layer('saved_bidir_1').get_weights()\n",
    "\n",
    "shuffled_gru_1_kernel_weight_forward = shuffled_gru_1_kernel_weight_forward.T\n",
    "shuffled_gru_1_recurrent_weight_forward = shuffled_gru_1_recurrent_weight_forward.T\n",
    "shuffled_gru_1_kernel_bias_forward = shuffled_gru_1_bias_bundle_forward[0, :]\n",
    "shuffled_gru_1_recurrent_bias_forward = shuffled_gru_1_bias_bundle_forward[1, :]\n",
    "\n",
    "shuffled_gru_1_kernel_weight_backward = shuffled_gru_1_kernel_weight_backward.T\n",
    "shuffled_gru_1_recurrent_weight_backward = shuffled_gru_1_recurrent_weight_backward.T\n",
    "shuffled_gru_1_kernel_bias_backward = shuffled_gru_1_bias_bundle_backward[0, :]\n",
    "shuffled_gru_1_recurrent_bias_backward = shuffled_gru_1_bias_bundle_backward[1, :]\n",
    "\n",
    "dense_1_weight, dense_1_bias = saved_predictor.get_layer('saved_dense_1').get_weights()\n",
    "dense_iso_weight, dense_iso_bias = saved_predictor.get_layer('saved_dense_2').get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward weights\n",
    "\n",
    "gru_1_kernel_weight_forward = np.concatenate([\n",
    "    shuffled_gru_1_kernel_weight_forward[64:128, :],\n",
    "    shuffled_gru_1_kernel_weight_forward[0:64, :],\n",
    "    shuffled_gru_1_kernel_weight_forward[128:192, :]\n",
    "], axis=0)\n",
    "\n",
    "gru_1_recurrent_weight_forward = np.concatenate([\n",
    "    shuffled_gru_1_recurrent_weight_forward[64:128, :],\n",
    "    shuffled_gru_1_recurrent_weight_forward[0:64, :],\n",
    "    shuffled_gru_1_recurrent_weight_forward[128:192, :]\n",
    "], axis=0)\n",
    "\n",
    "gru_1_kernel_bias_forward = np.concatenate([\n",
    "    shuffled_gru_1_kernel_bias_forward[64:128],\n",
    "    shuffled_gru_1_kernel_bias_forward[0:64],\n",
    "    shuffled_gru_1_kernel_bias_forward[128:192]\n",
    "], axis=0)\n",
    "\n",
    "gru_1_recurrent_bias_forward = np.concatenate([\n",
    "    shuffled_gru_1_recurrent_bias_forward[64:128],\n",
    "    shuffled_gru_1_recurrent_bias_forward[0:64],\n",
    "    shuffled_gru_1_recurrent_bias_forward[128:192]\n",
    "], axis=0)\n",
    "\n",
    "#Backward weights\n",
    "\n",
    "gru_1_kernel_weight_backward = np.concatenate([\n",
    "    shuffled_gru_1_kernel_weight_backward[64:128, :],\n",
    "    shuffled_gru_1_kernel_weight_backward[0:64, :],\n",
    "    shuffled_gru_1_kernel_weight_backward[128:192, :]\n",
    "], axis=0)\n",
    "\n",
    "gru_1_recurrent_weight_backward = np.concatenate([\n",
    "    shuffled_gru_1_recurrent_weight_backward[64:128, :],\n",
    "    shuffled_gru_1_recurrent_weight_backward[0:64, :],\n",
    "    shuffled_gru_1_recurrent_weight_backward[128:192, :]\n",
    "], axis=0)\n",
    "\n",
    "gru_1_kernel_bias_backward = np.concatenate([\n",
    "    shuffled_gru_1_kernel_bias_backward[64:128],\n",
    "    shuffled_gru_1_kernel_bias_backward[0:64],\n",
    "    shuffled_gru_1_kernel_bias_backward[128:192]\n",
    "], axis=0)\n",
    "\n",
    "gru_1_recurrent_bias_backward = np.concatenate([\n",
    "    shuffled_gru_1_recurrent_bias_backward[64:128],\n",
    "    shuffled_gru_1_recurrent_bias_backward[0:64],\n",
    "    shuffled_gru_1_recurrent_bias_backward[128:192]\n",
    "], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually transfer model weights from keras to pytorch\n",
    "\n",
    "with torch.no_grad() :\n",
    "    \n",
    "    model_pytorch.gru1_forward.weight_ih_l0 = nn.Parameter(torch.FloatTensor(gru_1_kernel_weight_forward))\n",
    "    model_pytorch.gru1_forward.weight_hh_l0 = nn.Parameter(torch.FloatTensor(gru_1_recurrent_weight_forward))\n",
    "    model_pytorch.gru1_forward.bias_ih_l0 = nn.Parameter(torch.FloatTensor(gru_1_kernel_bias_forward))\n",
    "    model_pytorch.gru1_forward.bias_hh_l0 = nn.Parameter(torch.FloatTensor(gru_1_recurrent_bias_forward))\n",
    "\n",
    "    model_pytorch.gru1_backward.weight_ih_l0 = nn.Parameter(torch.FloatTensor(gru_1_kernel_weight_backward))\n",
    "    model_pytorch.gru1_backward.weight_hh_l0 = nn.Parameter(torch.FloatTensor(gru_1_recurrent_weight_backward))\n",
    "    model_pytorch.gru1_backward.bias_ih_l0 = nn.Parameter(torch.FloatTensor(gru_1_kernel_bias_backward))\n",
    "    model_pytorch.gru1_backward.bias_hh_l0 = nn.Parameter(torch.FloatTensor(gru_1_recurrent_bias_backward))\n",
    "    \n",
    "    model_pytorch.fc1.weight = nn.Parameter(torch.FloatTensor(np.transpose(dense_1_weight, (1, 0))))\n",
    "    model_pytorch.fc1.bias = nn.Parameter(torch.FloatTensor(dense_1_bias))\n",
    "    \n",
    "    model_pytorch.fc2.weight = nn.Parameter(torch.FloatTensor(np.transpose(dense_iso_weight, (1, 0))))\n",
    "    model_pytorch.fc2.bias = nn.Parameter(torch.FloatTensor(dense_iso_bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save pytorch model\n",
    "\n",
    "torch.save(model_pytorch.state_dict(), \"saved_models/ppi_rnn_baker_big_set_5x_negatives_classifier_symmetric_drop_25_5x_negatives_balanced_partitioned_data_epoch_10_pytorch.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize sequence encoder\n",
    "\n",
    "seq_length = 81\n",
    "\n",
    "residue_map = {'D': 0, 'E': 1, 'V': 2, 'K': 3, 'R': 4, 'L': 5, 'S': 6, 'T': 7, 'N': 8, 'H': 9, 'A': 10, 'I': 11, 'G': 12, 'P': 13, 'Q': 14, 'Y': 15, 'W': 16, 'M': 17, 'F': 18, '#': 19}\n",
    "\n",
    "encoder = IdentityEncoder(seq_length, residue_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pytorch model\n",
    "\n",
    "model_pytorch = GRUClassifier(batch_size=1)\n",
    "\n",
    "_ = model_pytorch.load_state_dict(torch.load(\"saved_models/ppi_rnn_baker_big_set_5x_negatives_classifier_symmetric_drop_25_5x_negatives_balanced_partitioned_data_epoch_10_pytorch.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq 1 = TAEELLEVHKKSDRVTKEHLRVSEEILKVVEVLTRGEVSSEVLKRVLRKLEELTDKLRRVTEEQRRVVEKLN\n",
      "Seq 2 = DLEDLLRRLRRLVDEQRRLVEELERVSRRLEKAVRDNEDERELARLSREHSDIQDKHDKLAREILEVLKRLLERTE\n"
     ]
    }
   ],
   "source": [
    "#Binder DHD_154\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "seq_1 = \"TAEELLEVHKKSDRVTKEHLRVSEEILKVVEVLTRGEVSSEVLKRVLRKLEELTDKLRRVTEEQRRVVEKLN\"[:81]\n",
    "seq_2 = \"DLEDLLRRLRRLVDEQRRLVEELERVSRRLEKAVRDNEDERELARLSREHSDIQDKHDKLAREILEVLKRLLERTE\"[:81]\n",
    "\n",
    "print(\"Seq 1 = \" + seq_1)\n",
    "print(\"Seq 2 = \" + seq_2)\n",
    "\n",
    "encoder = IdentityEncoder(81, residue_map)\n",
    "\n",
    "test_onehot_1 = np.tile(np.expand_dims(np.expand_dims(encoder.encode(seq_1), axis=0), axis=0), (batch_size, 1, 1, 1))\n",
    "test_onehot_2 = np.tile(np.expand_dims(np.expand_dims(encoder.encode(seq_2), axis=0), axis=0), (batch_size, 1, 1, 1))\n",
    "\n",
    "test_len_1 = np.tile(np.array([[len(seq_1)]]), (batch_size, 1))\n",
    "test_len_2 = np.tile(np.array([[len(seq_2)]]), (batch_size, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred (keras)   = [0.853256]\n",
      "y_pred (pytorch) = [0.8532558]\n"
     ]
    }
   ],
   "source": [
    "#Predict using keras model\n",
    "\n",
    "y_pred_keras = saved_predictor.predict(x=[np.concatenate([test_onehot_1, test_onehot_2], axis=2)], batch_size=1)\n",
    "\n",
    "print(\"y_pred (keras)   = \" + str(y_pred_keras[0]))\n",
    "\n",
    "#Predict using pytorch model\n",
    "model_pytorch.eval()\n",
    "        \n",
    "input_var = Variable(torch.FloatTensor(np.transpose(np.concatenate([test_onehot_1, test_onehot_2], axis=2), (0, 3, 1, 2))))\n",
    "input_var = input_var.cuda() if model_pytorch.use_cuda else input_var\n",
    "\n",
    "y_pred_pytorch = model_pytorch(input_var).data.cpu().numpy()\n",
    "\n",
    "print(\"y_pred (pytorch) = \" + str(y_pred_pytorch[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36_fresh)",
   "language": "python",
   "name": "conda_pytorch_p36_fresh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
