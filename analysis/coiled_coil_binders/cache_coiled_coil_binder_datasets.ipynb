{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, CuDNNLSTM, CuDNNGRU, BatchNormalization, LocallyConnected2D, Permute, TimeDistributed, Bidirectional\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.layers.merge import _Merge\n",
    "import keras.losses\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import isolearn.keras as iso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "from sequence_logo_helper_protein import plot_protein_logo\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n",
    "\n",
    "class EpochVariableCallback(Callback) :\n",
    "    \n",
    "    def __init__(self, my_variable, my_func) :\n",
    "        self.my_variable = my_variable       \n",
    "        self.my_func = my_func\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}) :\n",
    "        K.set_value(self.my_variable, self.my_func(K.get_value(self.my_variable), epoch))\n",
    "\n",
    "\n",
    "class IdentityEncoder(iso.SequenceEncoder) :\n",
    "    \n",
    "    def __init__(self, seq_len, channel_map) :\n",
    "        super(IdentityEncoder, self).__init__('identity', (seq_len, len(channel_map)))\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.n_channels = len(channel_map)\n",
    "        self.encode_map = channel_map\n",
    "        self.decode_map = {\n",
    "            val : key for key, val in channel_map.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        encoding = np.zeros((self.seq_len, self.n_channels))\n",
    "        \n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        seq = ''\n",
    "    \n",
    "        for pos in range(0, encoding.shape[0]) :\n",
    "            argmax_nt = np.argmax(encoding[pos, :])\n",
    "            max_nt = np.max(encoding[pos, :])\n",
    "            if max_nt == 1 :\n",
    "                seq += self.decode_map[argmax_nt]\n",
    "            else :\n",
    "                seq += self.decode_map[-1]\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        encoding = np.array(encoding_mat[row_index, :].todense()).reshape(-1, 4)\n",
    "        return self.decode(encoding)\n",
    "\n",
    "class NopTransformer(iso.ValueTransformer) :\n",
    "    \n",
    "    def __init__(self, n_classes) :\n",
    "        super(NopTransformer, self).__init__('nop', (n_classes, ))\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "    \n",
    "    def transform(self, values) :\n",
    "        return values\n",
    "    \n",
    "    def transform_inplace(self, values, transform) :\n",
    "        transform[:] = values\n",
    "    \n",
    "    def transform_inplace_sparse(self, values, transform_mat, row_index) :\n",
    "        transform_mat[row_index, :] = np.ravel(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(pair_df) = 890124\n",
      "   Unnamed: 0                                       monomer_id_1  \\\n",
      "0           0  redesigned_closed_6_6_9_9middlesbobby_1_4_S_01...   \n",
      "1           1  redesigned_closed_6_8_9_9middlesbobby_1_4_S_40...   \n",
      "2           2  redesigned_closed_6_6_9_10middlesbobby_1_4_S_1...   \n",
      "3           3  redesigned_closed_5_7_9_9middlesbobby_1_1_S_43...   \n",
      "4           4  redesigned_closed_6_6_8_10middlesbobby_1_5_S_2...   \n",
      "\n",
      "                                        monomer_id_2  \\\n",
      "0  redesigned_closed_6_6_8_10middlesbobby_1_5_S_2...   \n",
      "1  redesigned_closed_5_7_8_10middlesbobby_1_2_S_0...   \n",
      "2  redesigned_closed_6_6_9_9middlesbobby_1_4_S_07...   \n",
      "3  redesigned_closed_5_6_9_9middlesbobby_1_1_S_25...   \n",
      "4  redesigned_closed_6_6_8_9middlesbobby_1_5_S_16...   \n",
      "\n",
      "                                         amino_seq_1  \\\n",
      "0  SEKDLLRLNREILEEIERIQKDLEELLERAERDAEGGLEELEKLVR...   \n",
      "1  SEKEVMKEQIRLIRENIKAQEEILRLLKELERKGVDKEVEEVIKRI...   \n",
      "2  DEEEILKILEENLRIQREIDRIHEEQVKALERITRRREDREEIEKL...   \n",
      "3  STEDIARELRKIIRRDKESKKEIKRVHDEQRELAKDAEDSRVVRRL...   \n",
      "4  SEKEIIKRLNKLNEDLTRLLETYRRLVEEVERAGALEEELRRRQRE...   \n",
      "\n",
      "                                         amino_seq_2  interacts  \n",
      "0  TSEENVERQREHVRTTDEAIKEMEKIIRLLEVVARGEMDRDELRKV...        0.0  \n",
      "1  STEEVERIVEEVERISRRVVEISRRVVEKIRELIRRMKNERLVELL...        0.0  \n",
      "2  RTRELLDEHRKLLEEQERQTKQDEELLREVERRLREELIEMAKDVQ...        0.0  \n",
      "3  GKEEVLEVAKRLLELQEKLQRLHEELQRILDDIVRRKNADDTLVRR...        0.0  \n",
      "4  SEKEELKRLLEESNKLLELVKEQLRLAEDALRKIAKKARGEVEILE...        0.0  \n",
      "Training set size = 801112\n",
      "Validation set size = 445\n",
      "Test set size = 88567\n"
     ]
    }
   ],
   "source": [
    "#Re-load cached dataframe (shuffled)\n",
    "\n",
    "dataset_name = \"coiled_coil_binders\"\n",
    "\n",
    "experiment = \"baker_big_set_5x_negatives\"\n",
    "\n",
    "pair_df = pd.read_csv(\"pair_df_\" + experiment + \"_in_shuffled.csv\", sep=\"\\t\")\n",
    "\n",
    "print(\"len(pair_df) = \" + str(len(pair_df)))\n",
    "\n",
    "print(pair_df.head())\n",
    "\n",
    "#Generate training and test set indexes\n",
    "valid_set_size = 0.0005\n",
    "test_set_size = 0.0995\n",
    "\n",
    "data_index = np.arange(len(pair_df), dtype=np.int)\n",
    "\n",
    "train_index = data_index[:-int(len(pair_df) * (valid_set_size + test_set_size))]\n",
    "valid_index = data_index[train_index.shape[0]:-int(len(pair_df) * test_set_size)]\n",
    "test_index = data_index[train_index.shape[0] + valid_index.shape[0]:]\n",
    "\n",
    "print('Training set size = ' + str(train_index.shape[0]))\n",
    "print('Validation set size = ' + str(valid_index.shape[0]))\n",
    "print('Test set size = ' + str(test_index.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size = 40000\n",
      "Test set size = 4000\n"
     ]
    }
   ],
   "source": [
    "#Sub-select smaller dataset\n",
    "\n",
    "n_train_pos = 40000\n",
    "n_train_neg = 0\n",
    "\n",
    "n_test_pos = 4000\n",
    "n_test_neg = 0\n",
    "\n",
    "orig_n_train = train_index.shape[0]\n",
    "orig_n_valid = valid_index.shape[0]\n",
    "orig_n_test = test_index.shape[0]\n",
    "\n",
    "train_index_pos = np.nonzero((pair_df.iloc[train_index]['interacts'] == 1).values)[0][:n_train_pos]\n",
    "train_index_neg = np.nonzero((pair_df.iloc[train_index]['interacts'] == 0).values)[0][:n_train_neg]\n",
    "\n",
    "train_index = np.concatenate([train_index_pos, train_index_neg], axis=0)\n",
    "np.random.shuffle(train_index)\n",
    "\n",
    "test_index_pos = np.nonzero((pair_df.iloc[test_index]['interacts'] == 1).values)[0][:n_test_pos] + orig_n_train + orig_n_valid\n",
    "test_index_neg = np.nonzero((pair_df.iloc[test_index]['interacts'] == 0).values)[0][:n_test_neg] + orig_n_train + orig_n_valid\n",
    "\n",
    "test_index = np.concatenate([test_index_pos, test_index_neg], axis=0)\n",
    "np.random.shuffle(test_index)\n",
    "\n",
    "print('Training set size = ' + str(train_index.shape[0]))\n",
    "print('Test set size = ' + str(test_index.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate sequence lengths\n",
    "\n",
    "pair_df['amino_seq_1_len'] = pair_df['amino_seq_1'].str.len()\n",
    "pair_df['amino_seq_2_len'] = pair_df['amino_seq_2'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>monomer_id_1</th>\n",
       "      <th>monomer_id_2</th>\n",
       "      <th>amino_seq_1</th>\n",
       "      <th>amino_seq_2</th>\n",
       "      <th>interacts</th>\n",
       "      <th>amino_seq_1_len</th>\n",
       "      <th>amino_seq_2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>redesigned_closed_6_6_9_9middlesbobby_1_4_S_01...</td>\n",
       "      <td>redesigned_closed_6_6_8_10middlesbobby_1_5_S_2...</td>\n",
       "      <td>SEKDLLRLNREILEEIERIQKDLEELLERAERDAEGGLEELEKLVR...</td>\n",
       "      <td>TSEENVERQREHVRTTDEAIKEMEKIIRLLEVVARGEMDRDELRKV...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>redesigned_closed_6_8_9_9middlesbobby_1_4_S_40...</td>\n",
       "      <td>redesigned_closed_5_7_8_10middlesbobby_1_2_S_0...</td>\n",
       "      <td>SEKEVMKEQIRLIRENIKAQEEILRLLKELERKGVDKEVEEVIKRI...</td>\n",
       "      <td>STEEVERIVEEVERISRRVVEISRRVVEKIRELIRRMKNERLVELL...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>redesigned_closed_6_6_9_10middlesbobby_1_4_S_1...</td>\n",
       "      <td>redesigned_closed_6_6_9_9middlesbobby_1_4_S_07...</td>\n",
       "      <td>DEEEILKILEENLRIQREIDRIHEEQVKALERITRRREDREEIEKL...</td>\n",
       "      <td>RTRELLDEHRKLLEEQERQTKQDEELLREVERRLREELIEMAKDVQ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>redesigned_closed_5_7_9_9middlesbobby_1_1_S_43...</td>\n",
       "      <td>redesigned_closed_5_6_9_9middlesbobby_1_1_S_25...</td>\n",
       "      <td>STEDIARELRKIIRRDKESKKEIKRVHDEQRELAKDAEDSRVVRRL...</td>\n",
       "      <td>GKEEVLEVAKRLLELQEKLQRLHEELQRILDDIVRRKNADDTLVRR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>redesigned_closed_6_6_8_10middlesbobby_1_5_S_2...</td>\n",
       "      <td>redesigned_closed_6_6_8_9middlesbobby_1_5_S_16...</td>\n",
       "      <td>SEKEIIKRLNKLNEDLTRLLETYRRLVEEVERAGALEEELRRRQRE...</td>\n",
       "      <td>SEKEELKRLLEESNKLLELVKEQLRLAEDALRKIAKKARGEVEILE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       monomer_id_1  \\\n",
       "0           0  redesigned_closed_6_6_9_9middlesbobby_1_4_S_01...   \n",
       "1           1  redesigned_closed_6_8_9_9middlesbobby_1_4_S_40...   \n",
       "2           2  redesigned_closed_6_6_9_10middlesbobby_1_4_S_1...   \n",
       "3           3  redesigned_closed_5_7_9_9middlesbobby_1_1_S_43...   \n",
       "4           4  redesigned_closed_6_6_8_10middlesbobby_1_5_S_2...   \n",
       "\n",
       "                                        monomer_id_2  \\\n",
       "0  redesigned_closed_6_6_8_10middlesbobby_1_5_S_2...   \n",
       "1  redesigned_closed_5_7_8_10middlesbobby_1_2_S_0...   \n",
       "2  redesigned_closed_6_6_9_9middlesbobby_1_4_S_07...   \n",
       "3  redesigned_closed_5_6_9_9middlesbobby_1_1_S_25...   \n",
       "4  redesigned_closed_6_6_8_9middlesbobby_1_5_S_16...   \n",
       "\n",
       "                                         amino_seq_1  \\\n",
       "0  SEKDLLRLNREILEEIERIQKDLEELLERAERDAEGGLEELEKLVR...   \n",
       "1  SEKEVMKEQIRLIRENIKAQEEILRLLKELERKGVDKEVEEVIKRI...   \n",
       "2  DEEEILKILEENLRIQREIDRIHEEQVKALERITRRREDREEIEKL...   \n",
       "3  STEDIARELRKIIRRDKESKKEIKRVHDEQRELAKDAEDSRVVRRL...   \n",
       "4  SEKEIIKRLNKLNEDLTRLLETYRRLVEEVERAGALEEELRRRQRE...   \n",
       "\n",
       "                                         amino_seq_2  interacts  \\\n",
       "0  TSEENVERQREHVRTTDEAIKEMEKIIRLLEVVARGEMDRDELRKV...        0.0   \n",
       "1  STEEVERIVEEVERISRRVVEISRRVVEKIRELIRRMKNERLVELL...        0.0   \n",
       "2  RTRELLDEHRKLLEEQERQTKQDEELLREVERRLREELIEMAKDVQ...        0.0   \n",
       "3  GKEEVLEVAKRLLELQEKLQRLHEELQRILDDIVRRKNADDTLVRR...        0.0   \n",
       "4  SEKEELKRLLEESNKLLELVKEQLRLAEDALRKIAKKARGEVEILE...        0.0   \n",
       "\n",
       "   amino_seq_1_len  amino_seq_2_len  \n",
       "0               70               76  \n",
       "1               68               75  \n",
       "2               76               68  \n",
       "3               76               73  \n",
       "4               70               77  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize sequence encoder\n",
    "\n",
    "seq_length = 81\n",
    "\n",
    "residue_map = {'D': 0, 'E': 1, 'V': 2, 'K': 3, 'R': 4, 'L': 5, 'S': 6, 'T': 7, 'N': 8, 'H': 9, 'A': 10, 'I': 11, 'G': 12, 'P': 13, 'Q': 14, 'Y': 15, 'W': 16, 'M': 17, 'F': 18, '#': 19}\n",
    "\n",
    "encoder = IdentityEncoder(seq_length, residue_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct data generators\n",
    "\n",
    "class CategoricalRandomizer :\n",
    "    \n",
    "    def __init__(self, case_range, case_probs) :\n",
    "        self.case_range = case_range\n",
    "        self.case_probs = case_probs\n",
    "        self.cases = 0\n",
    "        \n",
    "    def get_random_sample(self, index=None) :\n",
    "        if index is None :\n",
    "            return self.cases\n",
    "        else :\n",
    "            return self.cases[index]\n",
    "    \n",
    "    def generate_random_sample(self, batch_size=1, data_ids=None) :\n",
    "        self.cases = np.random.choice(self.case_range, size=batch_size, replace=True, p=self.case_probs)\n",
    "\n",
    "def get_amino_seq(row, index, flip_randomizer, homodimer_randomizer, max_seq_len=seq_length) :\n",
    "    \n",
    "    is_flip = True if flip_randomizer.get_random_sample(index=index) == 1 else False\n",
    "    is_homodimer = True if homodimer_randomizer.get_random_sample(index=index) == 1 else False\n",
    "    \n",
    "    amino_seq_1, amino_seq_2 = row['amino_seq_1'], row['amino_seq_2']\n",
    "    if is_flip :\n",
    "        amino_seq_1, amino_seq_2 = row['amino_seq_2'], row['amino_seq_1']\n",
    "    if is_homodimer and row['interacts'] < 0.5 :\n",
    "        amino_seq_2 = amino_seq_1\n",
    "    \n",
    "    return amino_seq_1, amino_seq_2\n",
    "\n",
    "flip_randomizer = CategoricalRandomizer(np.arange(2), np.array([0.5, 0.5]))\n",
    "homodimer_randomizer = CategoricalRandomizer(np.arange(2), np.array([0.95, 0.05]))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data_gens = {\n",
    "    gen_id : iso.DataGenerator(\n",
    "        idx,\n",
    "        { 'df' : pair_df },\n",
    "        batch_size=(idx.shape[0] // batch_size) * batch_size,\n",
    "        inputs = [\n",
    "            {\n",
    "                'id' : 'amino_seq_1',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                #'extractor' : lambda row, index, flip_randomizer=flip_randomizer, homodimer_randomizer=homodimer_randomizer: (get_amino_seq(row, index, flip_randomizer, homodimer_randomizer)[0] + \"#\" * seq_length)[:seq_length],\n",
    "                'extractor' : lambda row, index, flip_randomizer=flip_randomizer, homodimer_randomizer=homodimer_randomizer: get_amino_seq(row, index, flip_randomizer, homodimer_randomizer)[0],\n",
    "                'encoder' : IdentityEncoder(seq_length, residue_map),\n",
    "                'dim' : (1, seq_length, len(residue_map)),\n",
    "                'sparsify' : False\n",
    "            },\n",
    "            {\n",
    "                'id' : 'amino_seq_2',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                #'extractor' : lambda row, index, flip_randomizer=flip_randomizer, homodimer_randomizer=homodimer_randomizer: (get_amino_seq(row, index, flip_randomizer, homodimer_randomizer)[1] + \"#\" * seq_length)[:seq_length],\n",
    "                'extractor' : lambda row, index, flip_randomizer=flip_randomizer, homodimer_randomizer=homodimer_randomizer: get_amino_seq(row, index, flip_randomizer, homodimer_randomizer)[1],\n",
    "                'encoder' : IdentityEncoder(seq_length, residue_map),\n",
    "                'dim' : (1, seq_length, len(residue_map)),\n",
    "                'sparsify' : False\n",
    "            },\n",
    "            {\n",
    "                'id' : 'amino_seq_1_len',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                'extractor' : lambda row, index, flip_randomizer=flip_randomizer, homodimer_randomizer=homodimer_randomizer: len(get_amino_seq(row, index, flip_randomizer, homodimer_randomizer)[0]),\n",
    "                'encoder' : lambda t: t,\n",
    "                'dim' : (1,),\n",
    "                'sparsify' : False\n",
    "            },\n",
    "            {\n",
    "                'id' : 'amino_seq_2_len',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                'extractor' : lambda row, index, flip_randomizer=flip_randomizer, homodimer_randomizer=homodimer_randomizer: len(get_amino_seq(row, index, flip_randomizer, homodimer_randomizer)[1]),\n",
    "                'encoder' : lambda t: t,\n",
    "                'dim' : (1,),\n",
    "                'sparsify' : False\n",
    "            }\n",
    "        ],\n",
    "        outputs = [\n",
    "            {\n",
    "                'id' : 'interacts',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                'extractor' : lambda row, index: row['interacts'],\n",
    "                'transformer' : NopTransformer(1),\n",
    "                'dim' : (1,),\n",
    "                'sparsify' : False\n",
    "            }\n",
    "        ],\n",
    "        randomizers = [flip_randomizer, homodimer_randomizer],\n",
    "        shuffle = True\n",
    "    ) for gen_id, idx in [('train', train_index), ('valid', valid_index), ('test', test_index)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1_train.shape = (40000, 1, 81, 20)\n",
      "x_2_train.shape = (40000, 1, 81, 20)\n",
      "x_1_test.shape = (4000, 1, 81, 20)\n",
      "x_2_test.shape = (4000, 1, 81, 20)\n",
      "l_1_train.shape = (40000, 1)\n",
      "l2_train.shape = (40000, 1)\n",
      "l_1_test.shape = (4000, 1)\n",
      "l2_test.shape = (4000, 1)\n",
      "y_train.shape = (40000, 1)\n",
      "y_test.shape = (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data matrices\n",
    "\n",
    "[x_1_train, x_2_train, l_1_train, l_2_train], [y_train] = data_gens['train'][0]\n",
    "[x_1_test, x_2_test, l_1_test, l_2_test], [y_test] = data_gens['test'][0]\n",
    "\n",
    "print(\"x_1_train.shape = \" + str(x_1_train.shape))\n",
    "print(\"x_2_train.shape = \" + str(x_2_train.shape))\n",
    "print(\"x_1_test.shape = \" + str(x_1_test.shape))\n",
    "print(\"x_2_test.shape = \" + str(x_2_test.shape))\n",
    "\n",
    "print(\"l_1_train.shape = \" + str(l_1_train.shape))\n",
    "print(\"l2_train.shape = \" + str(l_2_train.shape))\n",
    "print(\"l_1_test.shape = \" + str(l_1_test.shape))\n",
    "print(\"l2_test.shape = \" + str(l_2_test.shape))\n",
    "\n",
    "print(\"y_train.shape = \" + str(y_train.shape))\n",
    "print(\"y_test.shape = \" + str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save processed dataset\n",
    "\n",
    "save_suffix = \"_pos_only\"\n",
    "\n",
    "np.savez(\n",
    "    dataset_name + \"_\" + experiment + save_suffix,\n",
    "    x_1_train=x_1_train,\n",
    "    x_2_train=x_2_train,\n",
    "    l_1_train=l_1_train,\n",
    "    l_2_train=l_2_train,\n",
    "    y_train=y_train,\n",
    "    x_1_test=x_1_test,\n",
    "    x_2_test=x_2_test,\n",
    "    l_1_test=l_1_test,\n",
    "    l_2_test=l_2_test,\n",
    "    y_test=y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data_df) = 481\n",
      "len(test_df) = 480\n",
      "                                        monomer_id_1  \\\n",
      "0  redesigned_closed_5_7_9_9middlesbobby_1_1_S_39...   \n",
      "1  redesigned_closed_6_6_9_9middlesbobby_1_4_S_07...   \n",
      "2  redesigned_closed_6_6_9_9middlesbobby_1_4_S_08...   \n",
      "3  redesigned_closed_5_6_9_10middlesscott_1_1_S_3...   \n",
      "4  redesigned_closed_6_6_9_10middlesbobby_1_4_S_1...   \n",
      "\n",
      "                                        monomer_id_2  \\\n",
      "0  redesigned_closed_5_7_9_9middlesbobby_1_1_S_39...   \n",
      "1  redesigned_closed_6_6_9_9middlesbobby_1_4_S_07...   \n",
      "2  redesigned_closed_6_6_9_9middlesbobby_1_4_S_08...   \n",
      "3  redesigned_closed_5_6_9_10middlesscott_1_1_S_3...   \n",
      "4  redesigned_closed_6_6_9_10middlesbobby_1_4_S_1...   \n",
      "\n",
      "                                         amino_seq_1  \\\n",
      "0  DEEELLKLIEDLLKSNKELLDLSKKNLRLLRELVRERNMDDTALRK...   \n",
      "1  SEKELLELLRELIEDLDRDVKLLRRNVDLHRRVAREGMREELIKKS...   \n",
      "2  SEEERITEIVKRVEELLRRYEELVKEYKRVLEELRRELREEEQKEL...   \n",
      "3  SDEEELDEIIKRSEEVMREVEEIDKRVEDIVRKAAKEGASELVKRS...   \n",
      "4  TVKELVKTLLDLTREQQRIDKEVHRTSLSLLEEAKDRGNEELVRRS...   \n",
      "\n",
      "                                         amino_seq_2  interacts  \\\n",
      "0  SVEEVIKESEKIKKESERVKRENEELIRRAEEIAKRRGPVRAVKEL...        1.0   \n",
      "1  SLKELIEEILRLAERHIELSEEHLRIQEKVLEDAGKREELLRESLE...        1.0   \n",
      "2  STKENLEIHEDNLRVLDENLKVLTEVVKLLRLVTKNTLDKSVIREI...        1.0   \n",
      "3  SIKELLEEILRLSRELVKEAERNVRELKRIVDKVRERNKQPEEVLK...        1.0   \n",
      "4  SEEESLDRIEREQTRVLKEVKDSLDKVRKILEDLEREGADEAIREL...        1.0   \n",
      "\n",
      "   amino_seq_1_len  amino_seq_2_len  \n",
      "0               73               72  \n",
      "1               72               74  \n",
      "2               76               72  \n",
      "3               72               77  \n",
      "4               73               72  \n"
     ]
    }
   ],
   "source": [
    "#Re-load cached dataframe (shuffled)\n",
    "\n",
    "dataset_name = \"coiled_coil_binders\"\n",
    "\n",
    "experiment = \"coiled_coil_binders_alyssa\"\n",
    "\n",
    "data_df = pd.read_csv(experiment + \".csv\", sep=\"\\t\")\n",
    "\n",
    "print(\"len(data_df) = \" + str(len(data_df)))\n",
    "\n",
    "test_df = data_df.copy().reset_index(drop=True)\n",
    "\n",
    "batch_size = 32\n",
    "test_df = test_df.iloc[:(len(test_df) // batch_size) * batch_size].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(test_df) = \" + str(len(test_df)))\n",
    "\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1_test.shape = (480, 1, 81, 20)\n",
      "x_2_test.shape = (480, 1, 81, 20)\n",
      "l_1_test.shape = (480, 1)\n",
      "l_2_test.shape = (480, 1)\n",
      "y_test.shape = (480, 1)\n"
     ]
    }
   ],
   "source": [
    "#Construct test data\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "test_gen = iso.DataGenerator(\n",
    "    np.arange(len(test_df), dtype=np.int),\n",
    "    { 'df' : test_df },\n",
    "    batch_size=(len(test_df) // batch_size) * batch_size,\n",
    "    inputs = [\n",
    "        {\n",
    "            'id' : 'amino_seq_1',\n",
    "            'source_type' : 'dataframe',\n",
    "            'source' : 'df',\n",
    "            #'extractor' : lambda row, index: (row['amino_seq_1'] + \"#\" * seq_length)[:seq_length],\n",
    "            'extractor' : lambda row, index: row['amino_seq_1'],\n",
    "            'encoder' : IdentityEncoder(seq_length, residue_map),\n",
    "            'dim' : (1, seq_length, len(residue_map)),\n",
    "            'sparsify' : False\n",
    "        },\n",
    "        {\n",
    "            'id' : 'amino_seq_2',\n",
    "            'source_type' : 'dataframe',\n",
    "            'source' : 'df',\n",
    "            #'extractor' : lambda row, index: row['amino_seq_2'] + \"#\" * seq_length)[:seq_length],\n",
    "            'extractor' : lambda row, index: row['amino_seq_2'],\n",
    "            'encoder' : IdentityEncoder(seq_length, residue_map),\n",
    "            'dim' : (1, seq_length, len(residue_map)),\n",
    "            'sparsify' : False\n",
    "        },\n",
    "        {\n",
    "            'id' : 'amino_seq_1_len',\n",
    "            'source_type' : 'dataframe',\n",
    "            'source' : 'df',\n",
    "            'extractor' : lambda row, index: len(row['amino_seq_1']),\n",
    "            'encoder' : lambda t: t,\n",
    "            'dim' : (1,),\n",
    "            'sparsify' : False\n",
    "        },\n",
    "        {\n",
    "            'id' : 'amino_seq_2_len',\n",
    "            'source_type' : 'dataframe',\n",
    "            'source' : 'df',\n",
    "            'extractor' : lambda row, index: len(row['amino_seq_2']),\n",
    "            'encoder' : lambda t: t,\n",
    "            'dim' : (1,),\n",
    "            'sparsify' : False\n",
    "        }\n",
    "    ],\n",
    "    outputs = [\n",
    "        {\n",
    "            'id' : 'interacts',\n",
    "            'source_type' : 'dataframe',\n",
    "            'source' : 'df',\n",
    "            'extractor' : lambda row, index: row['interacts'],\n",
    "            'transformer' : NopTransformer(1),\n",
    "            'dim' : (1,),\n",
    "            'sparsify' : False\n",
    "        }\n",
    "    ],\n",
    "    randomizers = [],\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "#Load data matrices\n",
    "\n",
    "[x_1_test, x_2_test, l_1_test, l_2_test], [y_test] = test_gen[0]\n",
    "\n",
    "print(\"x_1_test.shape = \" + str(x_1_test.shape))\n",
    "print(\"x_2_test.shape = \" + str(x_2_test.shape))\n",
    "print(\"l_1_test.shape = \" + str(l_1_test.shape))\n",
    "print(\"l_2_test.shape = \" + str(l_2_test.shape))\n",
    "\n",
    "print(\"y_test.shape = \" + str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save processed dataset\n",
    "\n",
    "save_suffix = \"\"\n",
    "\n",
    "np.savez(\n",
    "    dataset_name + \"_\" + experiment + save_suffix,\n",
    "    x_1_test=x_1_test,\n",
    "    x_2_test=x_2_test,\n",
    "    l_1_test=l_1_test,\n",
    "    l_2_test=l_2_test,\n",
    "    y_test=y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
