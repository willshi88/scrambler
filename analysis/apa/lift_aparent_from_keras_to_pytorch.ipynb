{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random, os, h5py, math, time, glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IdentityEncoder :\n",
    "    \n",
    "    def __init__(self, seq_len, channel_map) :\n",
    "        self.seq_len = seq_len\n",
    "        self.n_channels = len(channel_map)\n",
    "        self.encode_map = channel_map\n",
    "        self.decode_map = {\n",
    "            nt: ix for ix, nt in self.encode_map.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        encoding = np.zeros((self.seq_len, self.n_channels))\n",
    "        \n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        seq = ''\n",
    "    \n",
    "        for pos in range(0, encoding.shape[0]) :\n",
    "            argmax_nt = np.argmax(encoding[pos, :])\n",
    "            max_nt = np.max(encoding[pos, :])\n",
    "            seq += self.decode_map[argmax_nt]\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNClassifier(nn.Module) :\n",
    "    \n",
    "    def __init__(self, batch_size, lib_index=5, distal_pas=1.) :\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        lib_inp_numpy = np.zeros((batch_size, 13))\n",
    "        lib_inp_numpy[:, lib_index] = 1.\n",
    "        #self.lib_inp = Variable(torch.FloatTensor(lib_inp_numpy).to(torch.device('cuda:0')))\n",
    "        self.lib_inp = Variable(torch.FloatTensor(lib_inp_numpy))\n",
    "        \n",
    "        d_inp_numpy = np.zeros((batch_size, 1))\n",
    "        d_inp_numpy[:, 0] = distal_pas\n",
    "        #self.d_inp = Variable(torch.FloatTensor(d_inp_numpy).to(torch.device('cuda:0')))\n",
    "        self.d_inp = Variable(torch.FloatTensor(d_inp_numpy))\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 96, kernel_size=(1, 8))\n",
    "        self.maxpool_1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(96, 128, kernel_size=(1, 6))\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=94 * 128 + 1, out_features=256)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(in_features=256 + 13, out_features=1)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.use_cuda = True if torch.cuda.is_available() else False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool_1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = x.reshape(-1, 94 * 128)\n",
    "        \n",
    "        x = torch.cat([x, self.d_inp], dim=1)\n",
    "        x = F.relu(self.drop1(self.fc1(x)))\n",
    "        x = torch.cat([x, self.lib_inp], dim=1)\n",
    "        \n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pytorch model skeleton\n",
    "\n",
    "model_pytorch = CNNClassifier(batch_size=32, lib_index=4, distal_pas=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#Load APARENT Keras predictor model\n",
    "\n",
    "#Specfiy file path to pre-trained predictor network\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), '../../../aparent/saved_models')\n",
    "saved_predictor_model_name = 'aparent_plasmid_iso_cut_distalpas_all_libs_no_sampleweights_sgd.h5'\n",
    "saved_predictor_model_path = os.path.join(save_dir, saved_predictor_model_name)\n",
    "\n",
    "saved_predictor = load_model(saved_predictor_model_path)\n",
    "\n",
    "acgt_encoder = IdentityEncoder(205, {'A':0, 'C':1, 'G':2, 'T':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect weights from keras model\n",
    "\n",
    "conv_1_weight, conv_1_bias = saved_predictor.get_layer('conv2d_1').get_weights()\n",
    "conv_2_weight, conv_2_bias = saved_predictor.get_layer('conv2d_2').get_weights()\n",
    "\n",
    "dense_1_weight, dense_1_bias = saved_predictor.get_layer('dense_1').get_weights()\n",
    "dense_iso_weight, dense_iso_bias = saved_predictor.get_layer('dense_3').get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually transfer model weights from keras to pytorch\n",
    "\n",
    "with torch.no_grad() :\n",
    "    model_pytorch.conv1.weight = nn.Parameter(torch.FloatTensor(np.transpose(conv_1_weight, (3, 1, 2, 0))))\n",
    "    model_pytorch.conv1.bias = nn.Parameter(torch.FloatTensor(conv_1_bias))\n",
    "    \n",
    "    model_pytorch.conv2.weight = nn.Parameter(torch.FloatTensor(np.transpose(conv_2_weight, (3, 2, 1, 0))))\n",
    "    model_pytorch.conv2.bias = nn.Parameter(torch.FloatTensor(conv_2_bias))\n",
    "    \n",
    "    model_pytorch.fc1.weight = nn.Parameter(torch.FloatTensor(np.transpose(dense_1_weight, (1, 0))))\n",
    "    model_pytorch.fc1.bias = nn.Parameter(torch.FloatTensor(dense_1_bias))\n",
    "    \n",
    "    model_pytorch.fc2.weight = nn.Parameter(torch.FloatTensor(np.transpose(dense_iso_weight, (1, 0))))\n",
    "    model_pytorch.fc2.bias = nn.Parameter(torch.FloatTensor(dense_iso_bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save pytorch model\n",
    "\n",
    "torch.save(model_pytorch.state_dict(), \"saved_models/aparent_plasmid_iso_cut_distalpas_all_libs_no_sampleweights_sgd_pytorch.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data_df) = 34748 (loaded)\n"
     ]
    }
   ],
   "source": [
    "class MySequence :\n",
    "    def __init__(self) :\n",
    "        self.dummy = 1\n",
    "\n",
    "keras.utils.Sequence = MySequence\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "import pickle\n",
    "\n",
    "#Define dataset/experiment name\n",
    "dataset_name = \"apa_doubledope\"\n",
    "\n",
    "#Load cached dataframe\n",
    "cached_dict = pickle.load(open('apa_doubledope_cached_set.pickle', 'rb'))\n",
    "data_df = cached_dict['data_df']\n",
    "\n",
    "print(\"len(data_df) = \" + str(len(data_df)) + \" (loaded)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size = 31274\n",
      "Validation set size = 1737\n",
      "Test set size = 1737\n",
      "x_train.shape = (31264, 1, 205, 4)\n",
      "x_test.shape = (1728, 1, 205, 4)\n",
      "y_train.shape = (31264, 1)\n",
      "y_test.shape = (1728, 1)\n"
     ]
    }
   ],
   "source": [
    "#Make generators\n",
    "\n",
    "valid_set_size = 0.05\n",
    "test_set_size = 0.05\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Generate training and test set indexes\n",
    "data_index = np.arange(len(data_df), dtype=np.int)\n",
    "\n",
    "train_index = data_index[:-int(len(data_df) * (valid_set_size + test_set_size))]\n",
    "valid_index = data_index[train_index.shape[0]:-int(len(data_df) * test_set_size)]\n",
    "test_index = data_index[train_index.shape[0] + valid_index.shape[0]:]\n",
    "\n",
    "print('Training set size = ' + str(train_index.shape[0]))\n",
    "print('Validation set size = ' + str(valid_index.shape[0]))\n",
    "print('Test set size = ' + str(test_index.shape[0]))\n",
    "\n",
    "\n",
    "data_gens = {\n",
    "    gen_id : isol.DataGenerator(\n",
    "        idx,\n",
    "        {'df' : data_df},\n",
    "        batch_size=batch_size,\n",
    "        inputs = [\n",
    "            {\n",
    "                'id' : 'seq',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                'extractor' : isol.SequenceExtractor('padded_seq', start_pos=180, end_pos=180 + 205),\n",
    "                'encoder' : isol.OneHotEncoder(seq_length=205),\n",
    "                'dim' : (1, 205, 4),\n",
    "                'sparsify' : False\n",
    "            }\n",
    "        ],\n",
    "        outputs = [\n",
    "            {\n",
    "                'id' : 'hairpin',\n",
    "                'source_type' : 'dataframe',\n",
    "                'source' : 'df',\n",
    "                'extractor' : lambda row, index: row['proximal_usage'],\n",
    "                'transformer' : lambda t: t,\n",
    "                'dim' : (1,),\n",
    "                'sparsify' : False\n",
    "            }\n",
    "        ],\n",
    "        randomizers = [],\n",
    "        shuffle = True if gen_id == 'train' else False\n",
    "    ) for gen_id, idx in [('all', data_index), ('train', train_index), ('valid', valid_index), ('test', test_index)]\n",
    "}\n",
    "\n",
    "#Load data matrices\n",
    "\n",
    "x_train = np.concatenate([data_gens['train'][i][0][0] for i in range(len(data_gens['train']))], axis=0)\n",
    "x_test = np.concatenate([data_gens['test'][i][0][0] for i in range(len(data_gens['test']))], axis=0)\n",
    "\n",
    "y_train = np.concatenate([data_gens['train'][i][1][0] for i in range(len(data_gens['train']))], axis=0)\n",
    "y_test = np.concatenate([data_gens['test'][i][1][0] for i in range(len(data_gens['test']))], axis=0)\n",
    "\n",
    "print(\"x_train.shape = \" + str(x_train.shape))\n",
    "print(\"x_test.shape = \" + str(x_test.shape))\n",
    "\n",
    "print(\"y_train.shape = \" + str(y_train.shape))\n",
    "print(\"y_test.shape = \" + str(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pytorch model\n",
    "\n",
    "model_pytorch = CNNClassifier(batch_size=32, lib_index=4, distal_pas=1.)\n",
    "_ = model_pytorch.load_state_dict(torch.load(\"saved_models/aparent_plasmid_iso_cut_distalpas_all_libs_no_sampleweights_sgd_pytorch.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 1, 205)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(x_test[:1], (0, 3, 1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using keras model\n",
    "\n",
    "aparent_l_test = np.zeros((x_test.shape[0], 13))\n",
    "aparent_l_test[:, 4] = 1.\n",
    "\n",
    "aparent_d_test = np.ones((x_test.shape[0], 1))\n",
    "\n",
    "y_pred_keras = saved_predictor.predict(x=[np.transpose(x_test[:32], (0, 2, 3, 1)), aparent_l_test[:32], aparent_d_test[:32]], batch_size=1)[0]\n",
    "\n",
    "#Predict using pytorch model\n",
    "model_pytorch.eval()\n",
    "        \n",
    "input_var = Variable(torch.FloatTensor(np.transpose(x_test[:32], (0, 3, 1, 2))))\n",
    "input_var = input_var.cuda() if model_pytorch.use_cuda else input_var\n",
    "\n",
    "y_pred_pytorch = model_pytorch(input_var).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Sequence 0\n",
      "prob (keras)   = [0.0857]\n",
      "prob (pytorch) = [0.0857]\n",
      "--------------------\n",
      "Sequence 1\n",
      "prob (keras)   = [0.181]\n",
      "prob (pytorch) = [0.181]\n",
      "--------------------\n",
      "Sequence 2\n",
      "prob (keras)   = [0.7814]\n",
      "prob (pytorch) = [0.7814]\n",
      "--------------------\n",
      "Sequence 3\n",
      "prob (keras)   = [0.1501]\n",
      "prob (pytorch) = [0.1501]\n",
      "--------------------\n",
      "Sequence 4\n",
      "prob (keras)   = [0.27]\n",
      "prob (pytorch) = [0.27]\n",
      "--------------------\n",
      "Sequence 5\n",
      "prob (keras)   = [0.6723]\n",
      "prob (pytorch) = [0.6723]\n",
      "--------------------\n",
      "Sequence 6\n",
      "prob (keras)   = [0.9261]\n",
      "prob (pytorch) = [0.9261]\n",
      "--------------------\n",
      "Sequence 7\n",
      "prob (keras)   = [0.8405]\n",
      "prob (pytorch) = [0.8405]\n",
      "--------------------\n",
      "Sequence 8\n",
      "prob (keras)   = [0.5964]\n",
      "prob (pytorch) = [0.5964]\n",
      "--------------------\n",
      "Sequence 9\n",
      "prob (keras)   = [0.6466]\n",
      "prob (pytorch) = [0.6466]\n",
      "--------------------\n",
      "Sequence 10\n",
      "prob (keras)   = [0.0147]\n",
      "prob (pytorch) = [0.0147]\n",
      "--------------------\n",
      "Sequence 11\n",
      "prob (keras)   = [0.8999]\n",
      "prob (pytorch) = [0.8999]\n",
      "--------------------\n",
      "Sequence 12\n",
      "prob (keras)   = [0.417]\n",
      "prob (pytorch) = [0.417]\n",
      "--------------------\n",
      "Sequence 13\n",
      "prob (keras)   = [0.0981]\n",
      "prob (pytorch) = [0.0981]\n",
      "--------------------\n",
      "Sequence 14\n",
      "prob (keras)   = [0.8522]\n",
      "prob (pytorch) = [0.8522]\n",
      "--------------------\n",
      "Sequence 15\n",
      "prob (keras)   = [0.0664]\n",
      "prob (pytorch) = [0.0664]\n",
      "--------------------\n",
      "Sequence 16\n",
      "prob (keras)   = [0.6412]\n",
      "prob (pytorch) = [0.6412]\n",
      "--------------------\n",
      "Sequence 17\n",
      "prob (keras)   = [0.6919]\n",
      "prob (pytorch) = [0.6919]\n",
      "--------------------\n",
      "Sequence 18\n",
      "prob (keras)   = [0.0655]\n",
      "prob (pytorch) = [0.0655]\n",
      "--------------------\n",
      "Sequence 19\n",
      "prob (keras)   = [0.0926]\n",
      "prob (pytorch) = [0.0926]\n",
      "--------------------\n",
      "Sequence 20\n",
      "prob (keras)   = [0.6259]\n",
      "prob (pytorch) = [0.6259]\n",
      "--------------------\n",
      "Sequence 21\n",
      "prob (keras)   = [0.5891]\n",
      "prob (pytorch) = [0.5891]\n",
      "--------------------\n",
      "Sequence 22\n",
      "prob (keras)   = [0.0698]\n",
      "prob (pytorch) = [0.0698]\n",
      "--------------------\n",
      "Sequence 23\n",
      "prob (keras)   = [0.1962]\n",
      "prob (pytorch) = [0.1962]\n",
      "--------------------\n",
      "Sequence 24\n",
      "prob (keras)   = [0.1207]\n",
      "prob (pytorch) = [0.1207]\n",
      "--------------------\n",
      "Sequence 25\n",
      "prob (keras)   = [0.5372]\n",
      "prob (pytorch) = [0.5372]\n",
      "--------------------\n",
      "Sequence 26\n",
      "prob (keras)   = [0.8544]\n",
      "prob (pytorch) = [0.8544]\n",
      "--------------------\n",
      "Sequence 27\n",
      "prob (keras)   = [0.4051]\n",
      "prob (pytorch) = [0.4051]\n",
      "--------------------\n",
      "Sequence 28\n",
      "prob (keras)   = [0.4241]\n",
      "prob (pytorch) = [0.4241]\n",
      "--------------------\n",
      "Sequence 29\n",
      "prob (keras)   = [0.8912]\n",
      "prob (pytorch) = [0.8912]\n",
      "--------------------\n",
      "Sequence 30\n",
      "prob (keras)   = [0.2052]\n",
      "prob (pytorch) = [0.2052]\n",
      "--------------------\n",
      "Sequence 31\n",
      "prob (keras)   = [0.8396]\n",
      "prob (pytorch) = [0.8396]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, [p_keras, p_pytorch] in enumerate(zip(y_pred_keras.tolist(), y_pred_pytorch.tolist())) :\n",
    "    print(\"--------------------\")\n",
    "    print(\"Sequence \" + str(i))\n",
    "    print(\"prob (keras)   = \" + str(np.round(p_keras, 4)))\n",
    "    print(\"prob (pytorch) = \" + str(np.round(p_pytorch, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36_fresh)",
   "language": "python",
   "name": "conda_pytorch_p36_fresh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
