{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "import random, os, h5py, math, time, glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IdentityEncoder :\n",
    "    \n",
    "    def __init__(self, seq_len, channel_map) :\n",
    "        self.seq_len = seq_len\n",
    "        self.n_channels = len(channel_map)\n",
    "        self.encode_map = channel_map\n",
    "        self.decode_map = {\n",
    "            nt: ix for ix, nt in self.encode_map.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        encoding = np.zeros((self.seq_len, self.n_channels))\n",
    "        \n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        seq = ''\n",
    "    \n",
    "        for pos in range(0, encoding.shape[0]) :\n",
    "            argmax_nt = np.argmax(encoding[pos, :])\n",
    "            max_nt = np.max(encoding[pos, :])\n",
    "            seq += self.decode_map[argmax_nt]\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNClassifier(nn.Module) :\n",
    "    \n",
    "    def __init__(self, batch_size) :\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 120, kernel_size=(1, 8), padding=(0, 4))\n",
    "        self.conv2 = nn.Conv2d(120, 120, kernel_size=(1, 8), padding=(0, 4))\n",
    "        self.conv3 = nn.Conv2d(120, 120, kernel_size=(1, 8), padding=(0, 4))\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=50 * 120, out_features=40)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(in_features=40, out_features=1)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.use_cuda = True if torch.cuda.is_available() else False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))[..., 1:]\n",
    "        x = F.relu(self.conv2(x))[..., 1:]\n",
    "        x = F.relu(self.conv3(x))[..., 1:]\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = x.reshape(-1, 50 * 120)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))#F.relu(self.drop1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pytorch model skeleton\n",
    "\n",
    "model_pytorch = CNNClassifier(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/pytorch_p36_fresh/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#Load Predictor\n",
    "predictor_path = 'optimusRetrainedMain.hdf5'\n",
    "\n",
    "saved_predictor = load_model(predictor_path)\n",
    "\n",
    "saved_predictor.trainable = False\n",
    "saved_predictor.compile(optimizer=keras.optimizers.SGD(lr=0.1), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 50, 120)           3960      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 120)           115320    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 120)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 50, 120)           115320    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 120)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                240040    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 474,681\n",
      "Trainable params: 0\n",
      "Non-trainable params: 474,681\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect weights from keras model\n",
    "\n",
    "conv_1_weight, conv_1_bias = saved_predictor.get_layer('conv1d_1').get_weights()\n",
    "conv_2_weight, conv_2_bias = saved_predictor.get_layer('conv1d_2').get_weights()\n",
    "conv_3_weight, conv_3_bias = saved_predictor.get_layer('conv1d_3').get_weights()\n",
    "\n",
    "conv_1_weight = conv_1_weight[..., None, :]\n",
    "conv_2_weight = conv_2_weight[..., None, :]\n",
    "conv_3_weight = conv_3_weight[..., None, :]\n",
    "\n",
    "dense_1_weight, dense_1_bias = saved_predictor.get_layer('dense_1').get_weights()\n",
    "dense_2_weight, dense_2_bias = saved_predictor.get_layer('dense_2').get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually transfer model weights from keras to pytorch\n",
    "\n",
    "with torch.no_grad() :\n",
    "    model_pytorch.conv1.weight = nn.Parameter(torch.FloatTensor(np.transpose(conv_1_weight, (3, 1, 2, 0))))\n",
    "    model_pytorch.conv1.bias = nn.Parameter(torch.FloatTensor(conv_1_bias))\n",
    "    \n",
    "    model_pytorch.conv2.weight = nn.Parameter(torch.FloatTensor(np.transpose(conv_2_weight, (3, 1, 2, 0))))\n",
    "    model_pytorch.conv2.bias = nn.Parameter(torch.FloatTensor(conv_2_bias))\n",
    "    \n",
    "    model_pytorch.conv3.weight = nn.Parameter(torch.FloatTensor(np.transpose(conv_3_weight, (3, 1, 2, 0))))\n",
    "    model_pytorch.conv3.bias = nn.Parameter(torch.FloatTensor(conv_3_bias))\n",
    "    \n",
    "    model_pytorch.fc1.weight = nn.Parameter(torch.FloatTensor(np.transpose(dense_1_weight, (1, 0))))\n",
    "    model_pytorch.fc1.bias = nn.Parameter(torch.FloatTensor(dense_1_bias))\n",
    "    \n",
    "    model_pytorch.fc2.weight = nn.Parameter(torch.FloatTensor(np.transpose(dense_2_weight, (1, 0))))\n",
    "    model_pytorch.fc2.bias = nn.Parameter(torch.FloatTensor(dense_2_bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save pytorch model\n",
    "\n",
    "torch.save(model_pytorch.state_dict(), \"saved_models/optimusRetrainedMain_pytorch.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (15008, 1, 50, 4)\n",
      "y_train.shape = (15008, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#optimus 5-prime functions \n",
    "def test_data(df, model, test_seq, obs_col, output_col='pred'):\n",
    "    '''Predict mean ribosome load using model and test set UTRs'''\n",
    "    \n",
    "    # Scale the test set mean ribosome load\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df[obs_col].reshape(-1,1))\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(test_seq).reshape(-1)\n",
    "    \n",
    "    # Inverse scaled predicted mean ribosome load and return in a column labeled 'pred'\n",
    "    df.loc[:,output_col] = scaler.inverse_transform(predictions)\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encode(df, col='utr', seq_len=50):\n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1], 'n':[0,0,0,0]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    vectors=np.empty([len(df),seq_len,4])\n",
    "    \n",
    "    # Iterate through UTRs and one-hot encode\n",
    "    for i,seq in enumerate(df[col].str[:seq_len]): \n",
    "        seq = seq.lower()\n",
    "        a = np.array([nuc_d[x] for x in seq])\n",
    "        vectors[i] = a\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def r2(x,y):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "    return r_value**2\n",
    "\n",
    "\n",
    "#Train data\n",
    "e_train = pd.read_csv(\"bottom5KIFuAUGTop5KIFuAUG.csv\")\n",
    "e_train.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(e_train.loc[:,'rl'].values.reshape(-1,1))\n",
    "\n",
    "seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "x_train = seq_e_train\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]))\n",
    "y_train = np.array(e_train['scaled_rl'].values)\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "\n",
    "print(\"x_train.shape = \" + str(x_train.shape))\n",
    "print(\"y_train.shape = \" + str(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pytorch model\n",
    "\n",
    "model_pytorch = CNNClassifier(batch_size=32)\n",
    "_ = model_pytorch.load_state_dict(torch.load(\"saved_models/optimusRetrainedMain_pytorch.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 1, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(x_train[:1], (0, 3, 1, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using keras model\n",
    "\n",
    "y_pred_keras = saved_predictor.predict(x=[x_train[:32, 0, ...]], batch_size=1)\n",
    "\n",
    "#Predict using pytorch model\n",
    "model_pytorch.eval()\n",
    "        \n",
    "input_var = Variable(torch.FloatTensor(np.transpose(x_train[:32], (0, 3, 1, 2))))\n",
    "input_var = input_var.cuda() if model_pytorch.use_cuda else input_var\n",
    "\n",
    "y_pred_pytorch = model_pytorch(input_var).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Sequence 0\n",
      "prob (keras)   = [1.0168]\n",
      "prob (pytorch) = [1.0168]\n",
      "--------------------\n",
      "Sequence 1\n",
      "prob (keras)   = [0.5764]\n",
      "prob (pytorch) = [0.5764]\n",
      "--------------------\n",
      "Sequence 2\n",
      "prob (keras)   = [0.5024]\n",
      "prob (pytorch) = [0.5024]\n",
      "--------------------\n",
      "Sequence 3\n",
      "prob (keras)   = [0.8501]\n",
      "prob (pytorch) = [0.8501]\n",
      "--------------------\n",
      "Sequence 4\n",
      "prob (keras)   = [0.797]\n",
      "prob (pytorch) = [0.797]\n",
      "--------------------\n",
      "Sequence 5\n",
      "prob (keras)   = [0.6108]\n",
      "prob (pytorch) = [0.6108]\n",
      "--------------------\n",
      "Sequence 6\n",
      "prob (keras)   = [0.7627]\n",
      "prob (pytorch) = [0.7627]\n",
      "--------------------\n",
      "Sequence 7\n",
      "prob (keras)   = [0.8833]\n",
      "prob (pytorch) = [0.8833]\n",
      "--------------------\n",
      "Sequence 8\n",
      "prob (keras)   = [0.887]\n",
      "prob (pytorch) = [0.887]\n",
      "--------------------\n",
      "Sequence 9\n",
      "prob (keras)   = [0.9337]\n",
      "prob (pytorch) = [0.9337]\n",
      "--------------------\n",
      "Sequence 10\n",
      "prob (keras)   = [0.804]\n",
      "prob (pytorch) = [0.804]\n",
      "--------------------\n",
      "Sequence 11\n",
      "prob (keras)   = [0.7199]\n",
      "prob (pytorch) = [0.7199]\n",
      "--------------------\n",
      "Sequence 12\n",
      "prob (keras)   = [0.7503]\n",
      "prob (pytorch) = [0.7503]\n",
      "--------------------\n",
      "Sequence 13\n",
      "prob (keras)   = [1.0245]\n",
      "prob (pytorch) = [1.0245]\n",
      "--------------------\n",
      "Sequence 14\n",
      "prob (keras)   = [0.7559]\n",
      "prob (pytorch) = [0.7559]\n",
      "--------------------\n",
      "Sequence 15\n",
      "prob (keras)   = [0.866]\n",
      "prob (pytorch) = [0.866]\n",
      "--------------------\n",
      "Sequence 16\n",
      "prob (keras)   = [0.7118]\n",
      "prob (pytorch) = [0.7118]\n",
      "--------------------\n",
      "Sequence 17\n",
      "prob (keras)   = [0.6517]\n",
      "prob (pytorch) = [0.6517]\n",
      "--------------------\n",
      "Sequence 18\n",
      "prob (keras)   = [0.8044]\n",
      "prob (pytorch) = [0.8044]\n",
      "--------------------\n",
      "Sequence 19\n",
      "prob (keras)   = [0.6315]\n",
      "prob (pytorch) = [0.6315]\n",
      "--------------------\n",
      "Sequence 20\n",
      "prob (keras)   = [0.7152]\n",
      "prob (pytorch) = [0.7152]\n",
      "--------------------\n",
      "Sequence 21\n",
      "prob (keras)   = [0.9509]\n",
      "prob (pytorch) = [0.9509]\n",
      "--------------------\n",
      "Sequence 22\n",
      "prob (keras)   = [0.7993]\n",
      "prob (pytorch) = [0.7993]\n",
      "--------------------\n",
      "Sequence 23\n",
      "prob (keras)   = [0.7272]\n",
      "prob (pytorch) = [0.7272]\n",
      "--------------------\n",
      "Sequence 24\n",
      "prob (keras)   = [0.9668]\n",
      "prob (pytorch) = [0.9668]\n",
      "--------------------\n",
      "Sequence 25\n",
      "prob (keras)   = [0.7335]\n",
      "prob (pytorch) = [0.7335]\n",
      "--------------------\n",
      "Sequence 26\n",
      "prob (keras)   = [0.5467]\n",
      "prob (pytorch) = [0.5467]\n",
      "--------------------\n",
      "Sequence 27\n",
      "prob (keras)   = [0.9251]\n",
      "prob (pytorch) = [0.9251]\n",
      "--------------------\n",
      "Sequence 28\n",
      "prob (keras)   = [0.6966]\n",
      "prob (pytorch) = [0.6966]\n",
      "--------------------\n",
      "Sequence 29\n",
      "prob (keras)   = [0.827]\n",
      "prob (pytorch) = [0.827]\n",
      "--------------------\n",
      "Sequence 30\n",
      "prob (keras)   = [0.673]\n",
      "prob (pytorch) = [0.673]\n",
      "--------------------\n",
      "Sequence 31\n",
      "prob (keras)   = [0.222]\n",
      "prob (pytorch) = [0.222]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, [p_keras, p_pytorch] in enumerate(zip(y_pred_keras.tolist(), y_pred_pytorch.tolist())) :\n",
    "    print(\"--------------------\")\n",
    "    print(\"Sequence \" + str(i))\n",
    "    print(\"prob (keras)   = \" + str(np.round(p_keras, 4)))\n",
    "    print(\"prob (pytorch) = \" + str(np.round(p_pytorch, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36_fresh)",
   "language": "python",
   "name": "conda_pytorch_p36_fresh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
