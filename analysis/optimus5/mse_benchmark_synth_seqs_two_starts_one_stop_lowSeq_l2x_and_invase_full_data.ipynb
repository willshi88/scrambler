{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#12/29/20\n",
    "#runnign synthetic benchmark graphs for synthetic OR datasets generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#making benchmark images \n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, CuDNNLSTM, CuDNNGRU, BatchNormalization, LocallyConnected2D, Permute, TimeDistributed, Bidirectional\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.layers.merge import _Merge\n",
    "import keras.losses\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import isolearn.keras as iso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sequence_logo_helper import dna_letter_at, plot_dna_logo\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n",
    "\n",
    "class EpochVariableCallback(Callback) :\n",
    "    \n",
    "    def __init__(self, my_variable, my_func) :\n",
    "        self.my_variable = my_variable       \n",
    "        self.my_func = my_func\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}) :\n",
    "        K.set_value(self.my_variable, self.my_func(K.get_value(self.my_variable), epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ONLY RUN THIS CELL ONCE \n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "#Stochastic Binarized Neuron helper functions (Tensorflow)\n",
    "#ST Estimator code adopted from https://r2rt.com/beyond-binary-ternary-and-one-hot-neurons.html\n",
    "#See Github https://github.com/spitis/\n",
    "\n",
    "def st_sampled_softmax(logits):\n",
    "    with ops.name_scope(\"STSampledSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.squeeze(tf.multinomial(logits, 1), 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "def st_hardmax_softmax(logits):\n",
    "    with ops.name_scope(\"STHardmaxSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.argmax(nt_probs, 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "@ops.RegisterGradient(\"STMul\")\n",
    "def st_mul(op, grad):\n",
    "    return [grad, grad]\n",
    "\n",
    "#Gumbel Distribution Sampler\n",
    "def gumbel_softmax(logits, temperature=0.5) :\n",
    "    gumbel_dist = tf.contrib.distributions.RelaxedOneHotCategorical(temperature, logits=logits)\n",
    "    batch_dim = logits.get_shape().as_list()[0]\n",
    "    onehot_dim = logits.get_shape().as_list()[1]\n",
    "    return gumbel_dist.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PWM Masking and Sampling helper functions\n",
    "\n",
    "def mask_pwm(inputs) :\n",
    "    pwm, onehot_template, onehot_mask = inputs\n",
    "\n",
    "    return pwm * onehot_mask + onehot_template\n",
    "\n",
    "def sample_pwm_st(pwm_logits) :\n",
    "    n_sequences = K.shape(pwm_logits)[0]\n",
    "    seq_length = K.shape(pwm_logits)[2]\n",
    "\n",
    "    flat_pwm = K.reshape(pwm_logits, (n_sequences * seq_length, 4))\n",
    "    sampled_pwm = st_sampled_softmax(flat_pwm)\n",
    "\n",
    "    return K.reshape(sampled_pwm, (n_sequences, 1, seq_length, 4))\n",
    "\n",
    "def sample_pwm_gumbel(pwm_logits) :\n",
    "    n_sequences = K.shape(pwm_logits)[0]\n",
    "    seq_length = K.shape(pwm_logits)[2]\n",
    "\n",
    "    flat_pwm = K.reshape(pwm_logits, (n_sequences * seq_length, 4))\n",
    "    sampled_pwm = gumbel_softmax(flat_pwm, temperature=0.5)\n",
    "\n",
    "    return K.reshape(sampled_pwm, (n_sequences, 1, seq_length, 4))\n",
    "\n",
    "#Generator helper functions\n",
    "def initialize_sequence_templates(generator, sequence_templates, background_matrices) :\n",
    "\n",
    "    embedding_templates = []\n",
    "    embedding_masks = []\n",
    "    embedding_backgrounds = []\n",
    "\n",
    "    for k in range(len(sequence_templates)) :\n",
    "        sequence_template = sequence_templates[k]\n",
    "        onehot_template = iso.OneHotEncoder(seq_length=len(sequence_template))(sequence_template).reshape((1, len(sequence_template), 4))\n",
    "\n",
    "        for j in range(len(sequence_template)) :\n",
    "            if sequence_template[j] not in ['N', 'X'] :\n",
    "                nt_ix = np.argmax(onehot_template[0, j, :])\n",
    "                onehot_template[:, j, :] = -4.0\n",
    "                onehot_template[:, j, nt_ix] = 10.0\n",
    "            elif sequence_template[j] == 'X' :\n",
    "                onehot_template[:, j, :] = -1.0\n",
    "\n",
    "        onehot_mask = np.zeros((1, len(sequence_template), 4))\n",
    "        for j in range(len(sequence_template)) :\n",
    "            if sequence_template[j] == 'N' :\n",
    "                onehot_mask[:, j, :] = 1.0\n",
    "\n",
    "        embedding_templates.append(onehot_template.reshape(1, -1))\n",
    "        embedding_masks.append(onehot_mask.reshape(1, -1))\n",
    "        embedding_backgrounds.append(background_matrices[k].reshape(1, -1))\n",
    "\n",
    "    embedding_templates = np.concatenate(embedding_templates, axis=0)\n",
    "    embedding_masks = np.concatenate(embedding_masks, axis=0)\n",
    "    embedding_backgrounds = np.concatenate(embedding_backgrounds, axis=0)\n",
    "\n",
    "    generator.get_layer('template_dense').set_weights([embedding_templates])\n",
    "    generator.get_layer('template_dense').trainable = False\n",
    "\n",
    "    generator.get_layer('mask_dense').set_weights([embedding_masks])\n",
    "    generator.get_layer('mask_dense').trainable = False\n",
    "    \n",
    "    generator.get_layer('background_dense').set_weights([embedding_backgrounds])\n",
    "    generator.get_layer('background_dense').trainable = False\n",
    "\n",
    "#Generator construction function\n",
    "def build_sampler(batch_size, seq_length, n_classes=1, n_samples=1, sample_mode='st') :\n",
    "\n",
    "    #Initialize Reshape layer\n",
    "    reshape_layer = Reshape((1, seq_length, 4))\n",
    "    \n",
    "    #Initialize background matrix\n",
    "    onehot_background_dense = Embedding(n_classes, seq_length * 4, embeddings_initializer='zeros', name='background_dense')\n",
    "\n",
    "    #Initialize template and mask matrices\n",
    "    onehot_template_dense = Embedding(n_classes, seq_length * 4, embeddings_initializer='zeros', name='template_dense')\n",
    "    onehot_mask_dense = Embedding(n_classes, seq_length * 4, embeddings_initializer='ones', name='mask_dense')\n",
    "\n",
    "    #Initialize Templating and Masking Lambda layer\n",
    "    masking_layer = Lambda(mask_pwm, output_shape = (1, seq_length, 4), name='masking_layer')\n",
    "    background_layer = Lambda(lambda x: x[0] + x[1], name='background_layer')\n",
    "    \n",
    "    #Initialize PWM normalization layer\n",
    "    pwm_layer = Softmax(axis=-1, name='pwm')\n",
    "    \n",
    "    #Initialize sampling layers\n",
    "    sample_func = None\n",
    "    if sample_mode == 'st' :\n",
    "        sample_func = sample_pwm_st\n",
    "    elif sample_mode == 'gumbel' :\n",
    "        sample_func = sample_pwm_gumbel\n",
    "    \n",
    "    upsampling_layer = Lambda(lambda x: K.tile(x, [n_samples, 1, 1, 1]), name='upsampling_layer')\n",
    "    sampling_layer = Lambda(sample_func, name='pwm_sampler')\n",
    "    permute_layer = Lambda(lambda x: K.permute_dimensions(K.reshape(x, (n_samples, batch_size, 1, seq_length, 4)), (1, 0, 2, 3, 4)), name='permute_layer')\n",
    "    \n",
    "    def _sampler_func(class_input, raw_logits) :\n",
    "        \n",
    "        #Get Template and Mask\n",
    "        onehot_background = reshape_layer(onehot_background_dense(class_input))\n",
    "        onehot_template = reshape_layer(onehot_template_dense(class_input))\n",
    "        onehot_mask = reshape_layer(onehot_mask_dense(class_input))\n",
    "        \n",
    "        #Add Template and Multiply Mask\n",
    "        pwm_logits = masking_layer([background_layer([raw_logits, onehot_background]), onehot_template, onehot_mask])\n",
    "        \n",
    "        #Compute PWM (Nucleotide-wise Softmax)\n",
    "        pwm = pwm_layer(pwm_logits)\n",
    "        \n",
    "        #Tile each PWM to sample from and create sample axis\n",
    "        pwm_logits_upsampled = upsampling_layer(pwm_logits)\n",
    "        sampled_pwm = sampling_layer(pwm_logits_upsampled)\n",
    "        sampled_pwm = permute_layer(sampled_pwm)\n",
    "\n",
    "        sampled_mask = permute_layer(upsampling_layer(onehot_mask))\n",
    "        \n",
    "        return pwm_logits, pwm, sampled_pwm, onehot_mask, sampled_mask\n",
    "    \n",
    "    return _sampler_func\n",
    "\n",
    "#for formulation 2 graphing \n",
    "def returnXMeanLogits(e_train):\n",
    "    #returns x mean logits for displayign the pwm difference for the version 2 networks \n",
    "    #Visualize background sequence distribution\n",
    "    seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "    x_train = seq_e_train\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    pseudo_count = 1.0\n",
    "\n",
    "    x_mean = (np.sum(x_train, axis=(0, 1)) + pseudo_count) / (x_train.shape[0] + 4. * pseudo_count)\n",
    "    x_mean_logits = np.log(x_mean / (1. - x_mean))\n",
    "    return x_mean_logits, x_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimus5_synthetic_random_insert_if_uorf_2_start_1_stop_variable_loc_512\n",
      "(512, 1, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "#loading testing dataset \n",
    "\n",
    "from optimusFunctions import *\n",
    "import pandas as pd\n",
    "\n",
    "csv_to_open = \"optimus5_synthetic_random_insert_if_uorf_2_start_1_stop_variable_loc_512.csv\"\n",
    "\n",
    "\n",
    "dataset_name = csv_to_open.replace(\".csv\", \"\")\n",
    "print (dataset_name)\n",
    "data_df = pd.read_csv(\"./\" + csv_to_open) #open from scores folder \n",
    "#loaded test set which is sorted by number of start/stop signals \n",
    "\n",
    "seq_e_test = one_hot_encode(data_df, seq_len=50)\n",
    "benchmarkSet_seqs = seq_e_test\n",
    "x_test = np.reshape(benchmarkSet_seqs, (benchmarkSet_seqs.shape[0], 1, benchmarkSet_seqs.shape[1], benchmarkSet_seqs.shape[2]))\n",
    "print (x_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  15008  testing:  512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "e_train = pd.read_csv(\"bottom5KIFuAUGTop5KIFuAUG.csv\")\n",
    "\n",
    "print (\"training: \", e_train.shape[0], \" testing: \", x_test.shape[0])\n",
    "seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "x_mean_logits, x_mean = returnXMeanLogits(e_train)\n",
    "seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "x_train = seq_e_train\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  15008  testing:  512\n"
     ]
    }
   ],
   "source": [
    "#background \n",
    "\n",
    "#for formulation 2 graphing \n",
    "def returnXMeanLogits(e_train):\n",
    "    #returns x mean logits for displayign the pwm difference for the version 2 networks \n",
    "    #Visualize background sequence distribution\n",
    "    seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "    x_train = seq_e_train\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "    pseudo_count = 1.0\n",
    "\n",
    "    x_mean = (np.sum(x_train, axis=(0, 1)) + pseudo_count) / (x_train.shape[0] + 4. * pseudo_count)\n",
    "    x_mean_logits = np.log(x_mean / (1. - x_mean))\n",
    "    return x_mean_logits, x_mean\n",
    "\n",
    "e_train = pd.read_csv(\"bottom5KIFuAUGTop5KIFuAUG.csv\")\n",
    "print (\"training: \", e_train.shape[0], \" testing: \", x_test.shape[0])\n",
    "#one hot encode with optimus encoders \n",
    "seq_e_train = one_hot_encode(e_train,seq_len=50)\n",
    "x_mean_logits, x_mean = returnXMeanLogits(e_train)\n",
    "x_train = seq_e_train\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAAnCAYAAACc9WIYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAXhJREFUeJzt3LFKQ0EURdEzYm2plY3xQ/z/ysLCLj9gLTZyLZJYiGCCSA6yFrxq7jDTbgbempkAAAAA53Vx7gsAAAAAAh0AAAAqCHQAAAAoINABAACggEAHAACAAgIdAAAACgh0AAAAKCDQAQAAoIBABwAAgAICHQAAAAoIdAAAACgg0AEAAKCAQAcAAIACAh0AAAAKCHQAAAAoINABAACggEAHAACAAgIdAAAACgh0AAAAKCDQAQAAoIBABwAAgAICHQAAAAoIdAAAACgg0AEAAKDA5akb1somyUOSuyQ3Sa6SvCV5SvKS5DXJe5LZf59b9+c9z+TxV7cGAACAf+bkQE9ym+Q+ySbJdXaBvs0uwNeX2UOgf7cGAAAA7K2Z+XnqMLzW8cMAAABAZuaoB+uTAh0AAAD4G34SBwAAAAUEOgAAABQQ6AAAAFBAoAMAAEABgQ4AAAAFBDoAAAAUEOgAAABQQKADAABAAYEOAAAABQQ6AAAAFPgAbx8asfW9BQIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x46.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean conservation (bits) = 0.032049298346210106\n",
      "Mean KL Div against background (bits) = 1.9679329305814974\n"
     ]
    }
   ],
   "source": [
    "#Define sequence template for optimus\n",
    "\n",
    "sequence_template = 'N'*50\n",
    "sequence_mask = np.array([1 if sequence_template[j] == 'N' else 0 for j in range(len(sequence_template))])\n",
    "\n",
    "#Visualize background sequence distribution\n",
    "\n",
    "save_figs = True\n",
    "plot_dna_logo(np.copy(x_mean), sequence_template=sequence_template, figsize=(14, 0.65), logo_height=1.0, plot_start=0, plot_end=50)\n",
    "\n",
    "#Calculate mean training set conservation\n",
    "\n",
    "entropy = np.sum(x_mean * -np.log(x_mean), axis=-1) / np.log(2.0)\n",
    "conservation = 2.0 - entropy\n",
    "x_mean_conservation = np.sum(conservation) / np.sum(sequence_mask)\n",
    "print(\"Mean conservation (bits) = \" + str(x_mean_conservation))\n",
    "\n",
    "#Calculate mean training set kl-divergence against background\n",
    "x_train_clipped = np.clip(np.copy(x_train[:, 0, :, :]), 1e-8, 1. - 1e-8)\n",
    "kl_divs = np.sum(x_train_clipped * np.log(x_train_clipped / np.tile(np.expand_dims(x_mean, axis=0), (x_train_clipped.shape[0], 1, 1))), axis=-1) / np.log(2.0)\n",
    "x_mean_kl_divs = np.sum(kl_divs * sequence_mask, axis=-1) / np.sum(sequence_mask)\n",
    "x_mean_kl_div = np.mean(x_mean_kl_divs)\n",
    "print(\"Mean KL Div against background (bits) = \" + str(x_mean_kl_div))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize Encoder and Decoder networks\n",
    "batch_size = 32\n",
    "seq_length = 50\n",
    "n_samples = 128\n",
    "sample_mode = 'st'\n",
    "#sample_mode = 'gumbel'\n",
    "\n",
    "#Load sampler\n",
    "sampler = build_sampler(batch_size, seq_length, n_classes=1, n_samples=n_samples, sample_mode=sample_mode)\n",
    "\n",
    "#Load Predictor\n",
    "predictor_path = 'optimusRetrainedMain.hdf5'\n",
    "predictor = load_model(predictor_path)\n",
    "predictor.trainable = False\n",
    "predictor.compile(optimizer=keras.optimizers.SGD(lr=0.1), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build scrambler model\n",
    "dummy_class = Input(shape=(1,), name='dummy_class')\n",
    "input_logits = Input(shape=(1, seq_length, 4), name='input_logits')\n",
    "\n",
    "pwm_logits, pwm, sampled_pwm, pwm_mask, sampled_mask = sampler(dummy_class, input_logits)\n",
    "\n",
    "scrambler_model = Model([input_logits, dummy_class], [pwm_logits, pwm, sampled_pwm, pwm_mask, sampled_mask])\n",
    "\n",
    "#Initialize Sequence Templates and Masks\n",
    "initialize_sequence_templates(scrambler_model, [sequence_template], [x_mean_logits])\n",
    "\n",
    "scrambler_model.trainable = False\n",
    "scrambler_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "    loss='mean_squared_error'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n",
      "(512, 1, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "#open all score and reshape as needed \n",
    "\n",
    "file_names = [\n",
    "    \"l2x_\" + dataset_name +  \"_importance_scores_test.npy\",\n",
    "    \"invase_\" + dataset_name +  \"_conv_importance_scores_test.npy\",\n",
    "    \"l2x_\" + dataset_name +  \"_full_data_importance_scores_test.npy\",\n",
    "    \"invase_\" + dataset_name +  \"_conv_full_data_importance_scores_test.npy\",\n",
    "]\n",
    "#deepexplain_optimus_utr_OR_logic_synth_1_start_2_stops_method_integrated_gradients_importance_scores_test.npy\n",
    "\n",
    "model_names =[\n",
    "    \"l2x\",\n",
    "    \"invase\",\n",
    "    \"l2x_full_data\",\n",
    "    \"invase_full_data\",\n",
    "]\n",
    "\n",
    "model_importance_scores_test = [np.load(\"./\" + file_name) for file_name in file_names]\n",
    "\n",
    "for scores in model_importance_scores_test:\n",
    "    print (scores.shape)\n",
    "\n",
    "for model_i in range(len(model_names)) :\n",
    "    if model_importance_scores_test[model_i].shape[-1] > 1 :\n",
    "        model_importance_scores_test[model_i] = np.sum(model_importance_scores_test[model_i], axis=-1, keepdims=True)\n",
    "\n",
    "for scores in model_importance_scores_test:\n",
    "    print (scores.shape)\n",
    "    \n",
    "#reshape for mse script -> if not (3008, 1, 50, 1) make it that shape \n",
    "idealShape = model_importance_scores_test[0].shape\n",
    "print (idealShape)\n",
    "\n",
    "for model_i in range(len(model_names)) :\n",
    "    if model_importance_scores_test[model_i].shape != idealShape:\n",
    "        model_importance_scores_test[model_i] = np.expand_dims(model_importance_scores_test[model_i], 1)\n",
    "        \n",
    "for scores in model_importance_scores_test:\n",
    "    print (scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1, 50, 4)\n",
      "(512, 1, 50, 4)\n",
      "(512, 1)\n",
      "512/512 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "on_state_logit_val = 50.\n",
    "print (x_test.shape)\n",
    "\n",
    "dummy_test = np.zeros((x_test.shape[0], 1))\n",
    "x_test_logits = 2. * x_test - 1.\n",
    "\n",
    "print (x_test_logits.shape)\n",
    "print (dummy_test.shape)\n",
    "\n",
    "\n",
    "x_test_squeezed = np.squeeze(x_test)\n",
    "y_pred_ref = predictor.predict([x_test_squeezed], batch_size=32, verbose=True)[0]\n",
    "\n",
    "_, _, _, pwm_mask, sampled_mask = scrambler_model.predict([x_test_logits, dummy_test], batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'utr', 'gt', 'orig', 'l2x_0_76_quantile_MSE',\n",
      "       'l2x_0_82_quantile_MSE', 'l2x_0_88_quantile_MSE',\n",
      "       'invase_0_76_quantile_MSE', 'invase_0_82_quantile_MSE',\n",
      "       'invase_0_88_quantile_MSE', 'l2x_full_data_0_76_quantile_MSE',\n",
      "       'l2x_full_data_0_82_quantile_MSE', 'l2x_full_data_0_88_quantile_MSE',\n",
      "       'invase_full_data_0_76_quantile_MSE',\n",
      "       'invase_full_data_0_82_quantile_MSE',\n",
      "       'invase_full_data_0_88_quantile_MSE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_quantiles = [0.76, 0.82, 0.88]\n",
    "\n",
    "for name in model_names:\n",
    "    for quantile in feature_quantiles:\n",
    "        totalName = name + \"_\" + str(quantile).replace(\".\",\"_\") + \"_quantile_MSE\"\n",
    "        data_df[totalName] = None\n",
    "    \n",
    "print (data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking model 'l2x'...\n",
      "Feature quantile = 0.76\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.82\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.88\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Benchmarking model 'invase'...\n",
      "Feature quantile = 0.76\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.82\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.88\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Benchmarking model 'l2x_full_data'...\n",
      "Feature quantile = 0.76\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.82\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.88\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Benchmarking model 'invase_full_data'...\n",
      "Feature quantile = 0.76\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.82\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n",
      "Feature quantile = 0.88\n",
      "(512, 128, 1, 50, 4)\n",
      "Processing example 0...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_quantiles = [0.76, 0.82, 0.88]\n",
    "\n",
    "#batch_size = 128 \n",
    "from sklearn import metrics\n",
    "model_mses = []\n",
    "for model_i in range(len(model_names)) :\n",
    "    \n",
    "    print(\"Benchmarking model '\" + str(model_names[model_i]) + \"'...\")\n",
    "    \n",
    "    feature_quantile_mses = []\n",
    "    \n",
    "    for feature_quantile_i, feature_quantile in enumerate(feature_quantiles) :\n",
    "        \n",
    "        print(\"Feature quantile = \" + str(feature_quantile))\n",
    "    \n",
    "        if len(model_importance_scores_test[model_i].shape) >= 5 :\n",
    "            importance_scores_test = np.abs(model_importance_scores_test[model_i][feature_quantile_i, ...])\n",
    "        else :\n",
    "            importance_scores_test = np.abs(model_importance_scores_test[model_i])\n",
    "        \n",
    "        n_to_test = importance_scores_test.shape[0] // batch_size * batch_size\n",
    "        importance_scores_test = importance_scores_test[:n_to_test]\n",
    "        \n",
    "        importance_scores_test *= np.expand_dims(np.max(pwm_mask[:n_to_test], axis=-1), axis=-1)\n",
    "\n",
    "        quantile_vals = np.quantile(importance_scores_test, axis=(1, 2, 3), q=feature_quantile, keepdims=True)\n",
    "        quantile_vals = np.tile(quantile_vals, (1, importance_scores_test.shape[1], importance_scores_test.shape[2], importance_scores_test.shape[3]))\n",
    "\n",
    "        top_logits_test = np.zeros(importance_scores_test.shape)\n",
    "        top_logits_test[importance_scores_test > quantile_vals] = on_state_logit_val\n",
    "        \n",
    "        top_logits_test = np.tile(top_logits_test, (1, 1, 1, 4)) * x_test_logits[:n_to_test]\n",
    "\n",
    "        _, _, samples_test, _, _ = scrambler_model.predict([top_logits_test, dummy_test[:n_to_test]], batch_size=batch_size)\n",
    "        print (samples_test.shape)\n",
    "        msesPerPoint = []\n",
    "        for data_ix in range(samples_test.shape[0]) :\n",
    "            #for each sample, look at kl divergence for the 128 size batch generated \n",
    "            #for MSE, just track the pred vs original pred \n",
    "            if data_ix % 1000 == 0 :\n",
    "                print(\"Processing example \" + str(data_ix) + \"...\")\n",
    "            \n",
    "            #from optimus R^2, MSE, Pearson R script \n",
    "            justPred = np.expand_dims(np.expand_dims(x_test[data_ix, 0, :, :], axis=0), axis=-1)\n",
    "            justPredReshape = np.reshape(justPred, (1,50,4))\n",
    "            \n",
    "            expanded = np.expand_dims(samples_test[data_ix, :, 0, :, :], axis=-1) #batch size is 128 \n",
    "            expandedReshape = np.reshape(expanded, (n_samples, 50,4))\n",
    "            \n",
    "            y_test_hat_ref = predictor.predict(x=justPredReshape, batch_size=1)[0][0]\n",
    "            \n",
    "            y_test_hat = predictor.predict(x=[expandedReshape], batch_size=32)\n",
    "            \n",
    "            pwmGenerated = y_test_hat.tolist()\n",
    "            tempOriginals = [y_test_hat_ref]*y_test_hat.shape[0]\n",
    "            \n",
    "            asArrayOrig = np.array(tempOriginals)\n",
    "            asArrayGen = np.array(pwmGenerated)\n",
    "            squeezed = np.squeeze(asArrayGen)\n",
    "            mse = metrics.mean_squared_error(asArrayOrig, squeezed)\n",
    "            #msesPerPoint.append(mse)\n",
    "            totalName = model_names[model_i] + \"_\" + str(feature_quantile).replace(\".\",\"_\") + \"_quantile_MSE\"\n",
    "            data_df.at[data_ix, totalName] = mse\n",
    "            msesPerPoint.append(mse)\n",
    "        msesPerPoint = np.array(msesPerPoint)\n",
    "        feature_quantile_mses.append(msesPerPoint)\n",
    "    model_mses.append(feature_quantile_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MSEs ---\n",
      "----------------   0.76   0.82   0.88\n",
      "L2X                2.49   2.51   2.61\n",
      "INVASE             2.08   2.24   2.47\n",
      "L2X_FULL_DATA      2.28   2.40   2.56\n",
      "INVASE_FULL_DATA   2.77   2.80   2.85\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Store benchmark results as tables\n",
    "\n",
    "save_figs = False\n",
    "\n",
    "mse_table = np.zeros((len(model_mses), len(model_mses[0])))\n",
    "\n",
    "for i, model_name in enumerate(model_names) :\n",
    "    \n",
    "    for j, feature_quantile in enumerate(feature_quantiles) :\n",
    "        \n",
    "        mse_table[i, j] = np.mean(model_mses[i][j])\n",
    "\n",
    "#Plot and store mse table\n",
    "f = plt.figure(figsize = (4, 6))\n",
    "\n",
    "cells = np.round(mse_table, 3).tolist()\n",
    "\n",
    "print(\"--- MSEs ---\")\n",
    "max_len = np.max([len(model_name.upper().replace(\"\\n\", \" \")) for model_name in model_names])\n",
    "print((\"-\" * max_len) + \"   \" + \"   \".join([(str(feature_quantile) + \"0\")[:4] for feature_quantile in feature_quantiles]))\n",
    "for i in range(len(cells)) :\n",
    "    \n",
    "    curr_len = len([model_name.upper().replace(\"\\n\", \" \") for model_name in model_names][i])\n",
    "    row_str = [model_name.upper().replace(\"\\n\", \" \") for model_name in model_names][i] + (\" \" * (max_len - curr_len))\n",
    "    \n",
    "    for j in range(len(cells[i])) :\n",
    "        cells[i][j] = (str(cells[i][j]) + \"00000\")[:4]\n",
    "        \n",
    "        row_str += \"   \" + cells[i][j]\n",
    "    \n",
    "    print(row_str)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "table = plt.table(cellText=cells, rowLabels=[model_name.upper().replace(\"\\n\", \" \") for model_name in model_names], colLabels=feature_quantiles, loc='center')\n",
    "\n",
    "ax = plt.gca()\n",
    "#f.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs :\n",
    "    plt.savefig(dataset_name + \"_l2x_and_invase_full_data\" + \"_mse_table.png\", dpi=300, transparent=True)\n",
    "    plt.savefig(dataset_name + \"_l2x_and_invase_full_data\" + \"_mse_table.eps\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
